# üì¶ Navegaci√≥n por Visi√≥n - AutoModelCar

![ROS 2 Jazzy](https://img.shields.io/badge/ROS_2-Jazzy-blue?logo=ros&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.10+-yellow?logo=python&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

Este paquete (`navegacion_vision`) implementa un sistema de percepci√≥n visual para la navegaci√≥n aut√≥noma del **AutoModelCar**. Utiliza algoritmos de visi√≥n artificial para detectar carriles, trazar l√≠neas gu√≠a virtuales y calcular el error de direcci√≥n en tiempo real, robusteciendo el sistema frente a l√≠neas discontinuas o cambios de iluminaci√≥n.

## üöÄ Caracter√≠sticas Principales

* **Detecci√≥n de Carriles Robusta:** Algoritmo basado en segmentaci√≥n de color (HSV) y Regi√≥n de Inter√©s (ROI) din√°mica.
* **Manejo de L√≠neas Discontinuas:** Implementaci√≥n de memoria temporal y suavizado para mantener la trayectoria incluso cuando las l√≠neas del carril se pierden moment√°neamente.
* **Calibraci√≥n en Tiempo Real:** Interfaz gr√°fica (GUI) integrada que permite ajustar par√°metros "en vivo" sin detener el nodo:
    * Rango de color (HSV) para diferentes condiciones de luz.
    * Dimensiones del trapecio de visi√≥n (ROI).
    * Factores de suavizado y predicci√≥n.
* **Simulaci√≥n por Video:** Capacidad de inyectar archivos de video `.mp4` como si fueran un *stream* de c√°mara en vivo para pruebas *offline*.

## üõ†Ô∏è Requisitos del Sistema

* **Sistema Operativo:** Ubuntu 24.04 (Noble Numbat)
* **Middleware:** ROS 2 Jazzy Jalisco
* **Dependencias de Python:**
    ```bash
    pip install opencv-python numpy
    ```
* **Paquetes de ROS:**
    * `cv_bridge`
    * `sensor_msgs`
    * `std_msgs`

## üìÇ Dataset de Prueba

Para validar el funcionamiento sin el veh√≠culo f√≠sico, utilizamos grabaciones de conducci√≥n real.

* **üì• Dataset de Prueba (Video Corto):** [Descargar desde Google Drive](https://drive.google.com/file/d/1GfZ6-pa46afb4cbG6QSfBaIjuwr_Jlx5/view?usp=sharing)
    * *Nota:* Descarga este archivo y gu√°rdalo en tu equipo para realizar las pruebas.
* **Fuente Original:** [Ver en YouTube](https://www.youtube.com/watch?v=nABR88G_2cE)

## üíª Instalaci√≥n y Compilaci√≥n

1.  **Clonar el repositorio** en tu workspace (`src`):
    ```bash
    cd ~/tu_workspace/src
    git clone [https://github.com/OPEN-SOURCE-UPIITA/C-ROS.git](https://github.com/OPEN-SOURCE-UPIITA/C-ROS.git)
    ```

2.  **Instalar dependencias y compilar:**
    ```bash
    cd ~/tu_workspace
    rosdep install --from-paths src --ignore-src -r -y
    colcon build --packages-select navegacion_vision
    source install/setup.bash
    ```

## ‚öôÔ∏è Uso y Ejecuci√≥n

El sistema funciona con una arquitectura modular, por lo que requerir√°s abrir **tres terminales** distintas dentro de tu workspace.

> **Nota:** Aseg√∫rate de ejecutar `source install/setup.bash` en cada nueva terminal antes de correr los comandos.

### 1. Nodo de Adquisici√≥n (Terminal 1)
Este nodo publica el video como si fuera una c√°mara en vivo. En lugar de editar el c√≥digo, pasaremos la ruta del video descargado como un argumento directo.

```bash
source install/setup.bash
ros2 run navegacion_vision adq_video --ros-args -p video_source:="/ruta/absoluta/a/tu/dataset/Manejo_video_corto.mp4"
```

### 2. Nodo de Procesamiento (Terminal 2)
Inicia el algoritmo de visi√≥n artificial. Al ejecutarse, se abrir√° autom√°ticamente la ventana "Calibraci√≥n" para ajustar los filtros HSV y el ROI.

```bash
source install/setup.bash
ros2 run navegacion_vision proc_carril
```

### 3. Visualizaci√≥n (Terminal 3)
Utiliza rqt para monitorear tanto la imagen original como la procesada con las gu√≠as de direcci√≥n y el punto objetivo (bolita cian).

```bash
source install/setup.bash
ros2 run rqt_image_view rqt_image_view
```
